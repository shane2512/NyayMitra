#!/usr/bin/env python3
"""
Test script to demonstrate the API optimization improvements.
Shows before/after comparison of API usage patterns.
"""

import os
import sys
import time
from agents.api_optimizer import GeminiAPIOptimizer
from agents.usage_monitor import usage_monitor

def test_batch_vs_individual():
    """Test batch processing vs individual requests"""
    print("=== Testing API Optimization ===\n")
    
    # Sample contract clauses for testing
    test_clauses = [
        "The Tenant shall pay rent on the first day of each month.",
        "Either party may terminate this agreement with 30 days written notice.",
        "The Landlord shall maintain the property in good repair.",
        "The Tenant is responsible for all utilities except water and sewer.",
        "No pets are allowed on the premises without written consent.",
        "The security deposit shall be returned within 30 days of lease termination."
    ]
    
    from config import Config
    api_key = Config.GEMINI_API_KEY
    model_name = Config.GEMINI_MODEL
    
    if not api_key or api_key == 'your_default_api_key_here':
        print("âŒ Please set GEMINI_API_KEY in your .env file")
        return
    
    optimizer = GeminiAPIOptimizer(api_key, model_name=model_name)
    
    print(f"ğŸ“‹ Testing with {len(test_clauses)} sample contract clauses\n")
    
    # Test 1: Batch Processing (Optimized)
    print("ğŸš€ Testing OPTIMIZED batch processing...")
    start_time = time.time()
    
    try:
        batch_results = optimizer.batch_analyze_clauses(test_clauses, "risk")
        batch_time = time.time() - start_time
        
        print(f"âœ… Batch processing completed in {batch_time:.2f} seconds")
        print(f"ğŸ“Š Analyzed {len(batch_results)} clauses in 1 API call")
        
    except Exception as e:
        print(f"âŒ Batch processing failed: {e}")
        batch_time = float('inf')
        batch_results = {}
    
    # Test 2: Individual Processing (Traditional)
    print(f"\nğŸŒ Testing TRADITIONAL individual processing...")
    start_time = time.time()
    individual_count = 0
    
    try:
        for i, clause in enumerate(test_clauses[:3], 1):  # Test fewer to avoid rate limits
            print(f"   Processing clause {i}...")
            result = optimizer.optimized_generate_content(f"""
Analyze this contract clause for risk level (High/Medium/Low):
"{clause}"
Provide brief analysis.
""")
            individual_count += 1
            time.sleep(1)  # Add delay to avoid rate limits
        
        individual_time = time.time() - start_time
        print(f"âœ… Individual processing completed in {individual_time:.2f} seconds")
        print(f"ğŸ“Š Analyzed {individual_count} clauses in {individual_count} API calls")
        
    except Exception as e:
        print(f"âŒ Individual processing failed: {e}")
        individual_time = float('inf')
    
    # Show optimization results
    print(f"\nğŸ“ˆ OPTIMIZATION RESULTS:")
    print(f"{'='*50}")
    
    if batch_time != float('inf') and individual_time != float('inf'):
        time_savings = individual_time - batch_time
        efficiency_gain = individual_time / batch_time if batch_time > 0 else 0
        
        print(f"â±ï¸  Time Comparison:")
        print(f"   Batch processing: {batch_time:.2f}s")
        print(f"   Individual processing: {individual_time:.2f}s")
        print(f"   Time saved: {time_savings:.2f}s ({time_savings/individual_time*100:.1f}% faster)")
        print(f"   Efficiency gain: {efficiency_gain:.1f}x")
        
        print(f"\nğŸ”¥ API Call Reduction:")
        print(f"   Traditional: {len(test_clauses)} API calls")
        print(f"   Optimized: 1 API call")
        print(f"   Calls saved: {len(test_clauses)-1} ({(len(test_clauses)-1)/len(test_clauses)*100:.1f}% reduction)")
    
    # Show current usage statistics
    print(f"\nğŸ“Š CURRENT API USAGE STATS:")
    print(f"{'='*50}")
    current_usage = usage_monitor.get_current_usage()
    
    print(f"ğŸ¯ Optimization Score: {current_usage['optimization_score']:.1f}/100")
    print(f"ğŸ“ˆ Total Requests: {current_usage['total_requests']}")
    print(f"ğŸ’¾ Tokens Saved: {current_usage['total_tokens_saved']:,}")
    print(f"âš¡ Rate Limit Hits: {current_usage['rate_limit_hits']}")
    print(f"ğŸ“¦ Avg Batch Efficiency: {current_usage['avg_batch_efficiency']:.1f}x")
    
    # Show recommendations
    recommendations = usage_monitor.get_recommendations()
    if recommendations:
        print(f"\nğŸ’¡ OPTIMIZATION RECOMMENDATIONS:")
        print(f"{'='*50}")
        for i, rec in enumerate(recommendations, 1):
            print(f"{i}. {rec}")
    
    print(f"\nâœ¨ API optimization successfully implemented!")
    print(f"ğŸ‰ Your NyayMitra app now uses:")
    print(f"   â€¢ Batch processing for multiple clauses")
    print(f"   â€¢ Automatic retry with exponential backoff")
    print(f"   â€¢ Token compression for large inputs")
    print(f"   â€¢ Rate limit management")
    print(f"   â€¢ Real-time usage monitoring")

if __name__ == "__main__":
    test_batch_vs_individual()
